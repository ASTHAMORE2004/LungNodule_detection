# app.py â€“ Lungâ€‘Cancer EfficientNetB3 dashboard ğŸš€
import streamlit as st
import numpy  as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, roc_curve, auc, classification_report
from pathlib   import Path
from io        import BytesIO
from fpdf      import FPDF                 # pip install fpdf2
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import (
    array_to_img, img_to_array, load_img
)

from data_loader import loading_the_data, change_label_names, get_generators
from config      import DATA_DIR

# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
# â”‚ 0 â€¢ Page configuration & a tiny CSS theme              â”‚
# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
st.set_page_config(page_title="ğŸ¥  Lungâ€‘Cancer Classifier", layout="wide")
# Pastelâ€‘teal accents
st.markdown("""
<style>
    :root { --primary-color:#00A6A6; }
    .metric-container { background:#F1FCFC;border-radius:6px;padding:8px; }
    hr.section {border:none;border-top:3px solid #00A6A6;margin:1em 0;}
</style>
""", unsafe_allow_html=True)

# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
# â”‚ 1 â€¢ Sidebar widgets                                   â”‚
# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
with st.sidebar:
    st.header("âš™ï¸  Options")
    refresh = st.button("ğŸ”„Â ClearÂ cache & reload")
    class_mask = st.multiselect(
        "ğŸ¯Â Filter gallery by class",
        ["Lung_adenocarcinoma",
         "Lung squamous_cell_carcinoma",
         "Lung_benign_tissue"]
    )
    st.markdown("---")
    st.markdown(
        "ğŸ”¬ **EfficientNetâ€‘B3** Histopathology classifier  \n"
        "â€¢ *Adenocarcinoma*  \n"
        "â€¢ *Squamous cell carcinoma*  \n"
        "â€¢ *Benign tissue*"
    )
    st.markdown("---")
    btn_cm  = st.button("ğŸ“ŠÂ Confusion matrix")
    btn_roc = st.button("ğŸ“ˆÂ ROC curve")
    btn_pdf = st.button("ğŸ“„Â PDF report")

# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
# â”‚ 2 â€¢ Caching helpers                                   â”‚
# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
@st.cache_resource(hash_funcs={Path: lambda _: None})
def load_model_cached():
    return load_model("lung_cancer_model.h5")

@st.cache_resource
def load_generators():
    df = loading_the_data(DATA_DIR)
    change_label_names(df)
    return get_generators(df)

@st.cache_data
def quick_eval():
    """Tiny 200â€‘sample subset for fast metric cards."""
    model = load_model_cached()
    train_gen, val_gen, test_gen = load_generators()

    small = test_gen
    small.samples = 200
    small._set_index_array()
    small.batch_size = 32

    return (
        model.evaluate(train_gen, verbose=0),
        model.evaluate(val_gen,   verbose=0),
        model.evaluate(small,     verbose=0)
    )

@st.cache_data
def full_preds():
    """Full 1â€¯500â€‘image predictions (only on demand)."""
    model = load_model_cached()
    _, _, test_gen = load_generators()
    probs = model.predict(test_gen, verbose=0)
    preds = np.argmax(probs, axis=1)
    return test_gen.classes, preds, probs, list(test_gen.class_indices.keys())

# wipe caches if user clicked ğŸ”„
if refresh:
    load_model_cached.clear(); load_generators.clear()
    quick_eval.clear();        full_preds.clear()
    st.rerun()

# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
# â”‚ 3 â€¢ Tabs                                               â”‚
# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
tab_dash, tab_gallery, tab_explorer, tab_compare = st.tabs(
    ["ğŸ“Œ Dashboard", "ğŸ–¼ï¸ Gallery (20)", "ğŸ” Explorer", "ğŸ“Š Model Comparison"]
)

# â”€â”€ 3â€‘A â€¢ Dashboard â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with tab_dash:
    model = load_model_cached()
    train_m, val_m, test_m = quick_eval()

    tot_params       = f"{model.count_params():,}"
    trainable_params = f"{sum(np.prod(w.shape) for w in model.trainable_weights):,}"

    st.subheader("ğŸ“ˆÂ Quick metrics (200â€‘sample subset)")
    cols = st.columns(4)
    for col, (name, (loss, acc), color) in zip(
        cols,
        [("Train",train_m,"#A0E3E2"),
         ("Validation",val_m,"#FFD2B5"),
         ("Test",test_m,"#B4E197"),
         ("Params",(0,0), "#E0E0E0")]  # dummy for params column
    ):
        with col:
            st.markdown(f"<div class='metric-container'>", unsafe_allow_html=True)
            if name != "Params":
                st.metric(f"{name} Acc", f"{acc:.3f}")
                st.metric(f"{name} Loss", f"{loss:.3f}")
            else:
                st.metric("Total params", tot_params)
                st.metric("Trainable",   trainable_params)
            st.markdown("</div>", unsafe_allow_html=True)

    st.markdown("<hr class='section'>", unsafe_allow_html=True)

    # Heavy buttons (confâ€‘matrix / ROC / PDF)
    if btn_cm:
        y_true, y_pred, _, names = full_preds()
        st.subheader("ğŸ“ŠÂ Confusion matrix")
        cm = confusion_matrix(y_true, y_pred)
        fig, ax = plt.subplots(figsize=(6,4))
        sns.heatmap(cm, annot=True, fmt="d",
                    cmap="PuBuGn", cbar=False,
                    xticklabels=names, yticklabels=names, ax=ax)
        ax.set_xlabel("Predicted"); ax.set_ylabel("Actual")
        st.pyplot(fig)

    if btn_roc:
        y_true, _, prob, names = full_preds()
        y_onehot = pd.get_dummies(y_true).values
        fig, ax = plt.subplots()
        for i, n in enumerate(names):
            fpr, tpr, _ = roc_curve(y_onehot[:,i], prob[:,i])
            ax.plot(fpr, tpr, label=f"{n} (AUC={auc(fpr,tpr):.2f})")
        ax.plot([0,1],[0,1],"k--")
        ax.set_xlabel("False positive rate"); ax.set_ylabel("True positive rate")
        ax.set_title("ROC curve"); ax.legend()
        st.pyplot(fig)

    # Sanitiser for FPDF
    def sanitize(txt:str)->str:
        return txt.replace("â€‘","-").replace("â€“","-").encode("latin-1","replace").decode("latin-1")

    if btn_pdf:
        y_true, y_pred, _, names = full_preds()
        buf = BytesIO()
        pdf = FPDF(); pdf.add_page(); pdf.set_auto_page_break(True,15)
        pdf.set_font("Helvetica","B",16)
        pdf.cell(0,10,sanitize("Lungâ€‘Cancer Classifier Report"),0,1,"C")

        pdf.set_font("Helvetica","",12); pdf.ln(4)
        pdf.cell(0,8,"Classification report:",ln=1)
        rep = classification_report(y_true,y_pred,target_names=names,digits=3)
        for line in rep.splitlines():
            pdf.cell(0,6,sanitize(line),ln=1)
        pdf.output(buf)
        st.download_button("â¬‡ï¸Â Download PDF",
                           data=buf.getvalue(),
                           mime="application/pdf",
                           file_name="lung_classifier_report.pdf")

# â”€â”€ 3â€‘B â€¢ Gallery â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with tab_gallery:
    st.subheader("ğŸ–¼ï¸Â Sample images (20)")
    test_gen = load_generators()[2]; test_gen.reset()
    class_names_all = list(test_gen.class_indices.keys())
    idx_map = {name: idx for idx, name in enumerate(class_names_all)}

    # -- after  test_gen = load_generators()[2]  -----------------

    bx, by = next(test_gen)
    if len(bx) < 20: ex,ey = next(test_gen); bx=np.vstack([bx,ex]); by=np.vstack([by,ey])

    # Optional class filter
    if class_mask:
        keep_idx = [idx_map[c] for c in class_mask if c in idx_map]
        mask     = [np.argmax(y) in keep_idx for y in by]
        bx, by   = bx[mask], by[mask]


    if len(bx) == 0:
        st.warning("No images match the selected class filter.")
    else:
        bx, by = bx[:20], by[:20]
        pr  = load_model_cached().predict(bx, verbose=0)
        pi  = np.argmax(pr, axis=1)
        ci  = pr[np.arange(len(bx)), pi]
        ti  = np.argmax(by, axis=1)
        names = list(test_gen.class_indices.keys())
        cols_per_row = 4
        for r in range((len(bx)+cols_per_row-1)//cols_per_row):
            cols = st.columns(cols_per_row)
            for c in range(cols_per_row):
                idx = r*cols_per_row+c
                if idx >= len(bx): break
                with cols[c]:
                    st.image(array_to_img(bx[idx]), use_column_width=True)
                    st.markdown(
                        f"**Pred:** {names[pi[idx]]} "
                        f"({ci[idx]:.2f})  \n"
                        f"**True:** {names[ti[idx]]}"
                    )

# â”€â”€ 3â€‘C â€¢ Explorer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with tab_explorer:
    st.subheader("ğŸ”Â Prediction explorer")
    upl = st.file_uploader("Upload PNG/JPG slide", type=["png","jpg","jpeg"])
    rnd = st.button("ğŸ²Â Random test image")
    if upl or rnd:
        if upl:
            pil = load_img(upl, target_size=(224,224))
        else:
            test_gen = load_generators()[2]
            # pick a random index across the full test set
            rnd_idx  = np.random.randint(0, test_gen.samples)
            pil      = load_img(test_gen.filepaths[rnd_idx], target_size=(224,224))

        st.image(pil,width=250)

        arr = img_to_array(pil)/255.
        prob = load_model_cached().predict(arr[np.newaxis,...],verbose=0)[0]
        cls  = np.argmax(prob); conf=prob[cls]
        idx_to_name = {v:k for k,v in load_generators()[2].class_indices.items()}
        st.success(f"**Prediction:** {idx_to_name[cls]} | Confidence {conf:.2f}")


# â”€â”€ 3â€‘D â€¢ Model Comparison â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with tab_compare:
    st.subheader("ğŸ“Š Model Comparison: CNN vs EfficientNetB3")

    @st.cache_resource
    def load_cnn_model():
        return load_model("lung_cnn_model.h5")

    cnn_model = load_cnn_model()
    eff_model = load_model_cached()
    _, _, test_gen = load_generators()

    y_true = test_gen.classes
    class_names = list(test_gen.class_indices.keys())

    y_prob_cnn = cnn_model.predict(test_gen, verbose=0)
    y_pred_cnn = np.argmax(y_prob_cnn, axis=1)

    y_prob_eff = eff_model.predict(test_gen, verbose=0)
    y_pred_eff = np.argmax(y_prob_eff, axis=1)

    cm_cnn = confusion_matrix(y_true, y_pred_cnn)
    cm_eff = confusion_matrix(y_true, y_pred_eff)

    st.markdown("### ğŸ”„ Confusion Matrices")
    col1, col2 = st.columns(2)
    with col1:
        st.markdown("**CNN Confusion Matrix**")
        fig, ax = plt.subplots()
        sns.heatmap(cm_cnn, annot=True, fmt="d", cmap="Blues", xticklabels=class_names, yticklabels=class_names, ax=ax)
        ax.set_xlabel("Predicted"); ax.set_ylabel("Actual")
        st.pyplot(fig)

    with col2:
        st.markdown("**EfficientNetB3 Confusion Matrix**")
        fig, ax = plt.subplots()
        sns.heatmap(cm_eff, annot=True, fmt="d", cmap="Greens", xticklabels=class_names, yticklabels=class_names, ax=ax)
        ax.set_xlabel("Predicted"); ax.set_ylabel("Actual")
        st.pyplot(fig)

    st.markdown("### ğŸ“ƒ Classification Reports")
    st.markdown("**CNN:**")
    st.text(classification_report(y_true, y_pred_cnn, target_names=class_names))
    st.markdown("**EfficientNetB3:**")
    st.text(classification_report(y_true, y_pred_eff, target_names=class_names))

    st.markdown("### ğŸ“ˆ ROC-AUC Curve Comparison")
    y_true_1h = pd.get_dummies(y_true).values
    fig, axes = plt.subplots(1, 2, figsize=(12, 5))
    for i in range(len(class_names)):
        fpr, tpr, _ = roc_curve(y_true_1h[:, i], y_prob_cnn[:, i])
        axes[0].plot(fpr, tpr, label=f"{class_names[i]} (AUC={auc(fpr,tpr):.2f})")
    axes[0].plot([0,1],[0,1],'k--'); axes[0].legend(); axes[0].set_title("CNN ROC-AUC")

    for i in range(len(class_names)):
        fpr, tpr, _ = roc_curve(y_true_1h[:, i], y_prob_eff[:, i])
        axes[1].plot(fpr, tpr, label=f"{class_names[i]} (AUC={auc(fpr,tpr):.2f})")
    axes[1].plot([0,1],[0,1],'k--'); axes[1].legend(); axes[1].set_title("EfficientNetB3 ROC-AUC")
    st.pyplot(fig)

    st.markdown("### ğŸ“Œ Insights")
    st.info("""
- âœ… **CNN** achieved a nearly perfect AUC (1.00), indicating strong discriminative performance.
- âš¡ **EfficientNetB3**, while slightly below CNN in AUC (~0.99), shows better generalization and smoother validation performance.
- ğŸ§  For smaller datasets or faster training, CNN is a good fit.
- ğŸ” For robustness and future scalability, EfficientNetB3 is the better long-term model.
""")

st.success("âœ…Â Dashboard ready.")